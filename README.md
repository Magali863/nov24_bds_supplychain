
# ğŸŸ¢ğŸŸ¡ğŸ”´ Supply Chain Satisfaction des clients ğŸ”´ğŸŸ¡ğŸŸ¢

L'objectif de ce projet est de dÃ©velopper un modÃ¨le de machine learning capable d'analyser et de prÃ©dire la satisfaction client Ã  partir des commentaires des utilisateurs. En analysant les donnÃ©es textuelles des avis et les indicateurs pertinents qui Ã©mergent des commentaires, nous cherchons Ã  identifier des tendances positives ou nÃ©gatives et Ã  Ã©valuer le niveau de satisfaction des clients.

Nous nous interrogeons notamment sur la maniÃ¨re d'amÃ©liorer la satisfaction client en procÃ©dant Ã  une analyse rapide des commentaires des utilisateurs et en dÃ©tectant les Ã©volutions de la satisfaction Ã  travers des indicateurs clÃ©s.


## ğŸ“Œ FonctionnalitÃ©s du Projet

- Analyse des Commentaires : Extraction et traitement des donnÃ©es textuelles issues des avis clients.

- PrÃ©diction de la Satisfaction : Utilisation de modÃ¨les de machine learning pour prÃ©dire le niveau de satisfaction des clients.
## ğŸ“DonnÃ©es Sources

Nous avons recueilli des informations sur le site Trustpilot, une plateforme dÃ©diÃ©e aux avis sur les entreprises. Ainsi, nous avons constituÃ© un ensemble de donnÃ©es comprenant 33 563 avis concernant trois sociÃ©tÃ©s de la catÃ©gorie ordinateur et tÃ©lÃ©phone qui sont les suivantes : Materiel.net, Recommerce.com et Rebuy.
Vous trouverez ci-dessous la rÃ©paration des commentaires par entreprise : 
- Materiel.net â¡ï¸ 26.433
- Rebuy â¡ï¸ 4550
- Recommerce.com â¡ï¸ 2580

La constitution de notre jeu de donnÃ©es a Ã©tÃ© effectuÃ©e Ã  l'aide de la mÃ©thode de web scraping.
## ğŸ› Mode OpÃ©ratoire du Projet

Cette procÃ©dure opÃ©rationnelle dÃ©crit les Ã©tapes pour crÃ©er un DataFrame Ã  partir de donnÃ©es scrappÃ©es, effectuer le prÃ©processing, rÃ©aliser des visualisations, puis appliquer des techniques de machine learning et de deep learning afin de trouver la meilleure modÃ©lisation.

 
      ğŸ’» Ã‰tape 1 : CrÃ©ation du DataFrame - Webscraping
      
- Collecte des donnÃ©es :
  > Utilisation de webscraping BeautifulSoup pour extraire les donnÃ©es souhaitÃ©es Ã  partir d'une source web.
  > 
  > Convertir les donnÃ©es extraites en un DataFrame Ã  l'aide de pandas.
  >
- RÃ©fÃ©rences notebook sur Github :
  >
  >  https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/1_code%20%20WEB_SCRAPING%20sur%20le%20site%20truspilot_VD.ipynb
>   

     ğŸ›  Ã‰tape 2 : PrÃ©processing

- Nettoyage :
  > Supprimer les doublons et les valeurs manquantes.
  > 
  > Corriger les types de donnÃ©es (par exemple, convertir les dates en format datetime).

- Exploration de la base scrappÃ©e :
  > Utilisation des statistiques descriptives pour explorer les donnÃ©es.
  >
- RÃ©fÃ©rences notebook sur Github :
  >
  > https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/2_code%20_EXPLORATION_%26_PREPROCESSING%20_VD.ipynb
>

     ğŸ“Š Ã‰tape 3 : Data Visualization

- Visualisation des distributions des variables.

- WordCloud pour visualiser les mots les plus frÃ©quents dans les commentaires selon les notes de satisfaction client :
  
  > Notes de satisfaction client = 1 et 2
  > 
  > Note de satisfaction client = 3
  > 
  > Notes de satisfaction client = 4 et 5
  >
- RÃ©fÃ©rences notebook sur Github :
  >
  > https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/2_code%20_EXPLORATION_%26_PREPROCESSING%20_VD.ipynb
  > 
  > https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/4_code%20WORDCLOUD%20%26%20Note%20_Satisfaction_%20VD.ipynb
> 

     ğŸ›  Ã‰tape 4 : Feature Engineering

- Suppression des colonnes inutiles :
 
    > Identifier et supprimer les colonnes qui ne seront pas utiles pour la modÃ©lisation.
- CrÃ©ation de nouvelles caractÃ©ristiques :
  
     > DÃ©velopper des nouvelles variables qui pourraient amÃ©liorer la performance du modÃ¨le.
- Analyse de CorrÃ©lation :
  
     > Analyser la corrÃ©lation entre les variables explicatives et la variable cible
     >
- RÃ©fÃ©rences notebook sur Github :
     >
     > https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/3_code_FEATURE_ENGINEERING%20_%26_WORDCLOUD_VD.ipynb
     >
     >https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/Code_Emoticones.ipynb
 >

     ğŸ¤– Ã‰tape 5 : ModÃ©lisation 1

- PrÃ©paration des donnÃ©es :
  > Diviser les donnÃ©es en ensembles d'entraÃ®nement, de test et de validation.
  > Normaliser et encoder les donnÃ©es.
  > Equilibrer lâ€™ensemble dâ€™entrainement si le jeu de donnÃ©es est dÃ©sÃ©quilibrÃ©
   
- ModÃ©lisation :
  >Tester plusieurs modÃ¨les de classification : 
     RandomForestClassifier,
     LightGBM Classifier,
     RÃ©gression logistique.
  >
  > Optimiser les hyperparamÃ¨tres Ã  l'aide de RandomizedSearchCV.
  > 
  > Effectuer une validation croisÃ©e pour Ã©valuer la robustesse du modÃ¨le.
  > 
  > Analyser les erreurs et interprÃ©ter les rÃ©sultats
  >
- RÃ©fÃ©rences notebook sur Github :
  >
  >https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/5_code_MODELISATION%20BASE.ipynb
>

     ğŸ¤– Ã‰tape 6 : ModÃ©lisation 2


- IntÃ©gration de nouvelles caractÃ©ristiques NLP :
  >
  >CaractÃ©ristique pour dÃ©tecter la nÃ©gation dans le titre du commentaire.
  >
  > CaractÃ©ristique pour classer les sentiments en utilisant un modÃ¨le BERT ("nlptown/bert-base-multilingual-uncased-sentiment")

- RÃ©pÃ©ter la prÃ©paration et la modÃ©lisation :
  > Suivre les mÃªmes Ã©tapes de prÃ©paration des donnÃ©es et de modÃ©lisation que prÃ©cÃ©demment
  >
- RÃ©fÃ©rences notebook sur Github :
  >
  > https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/5.2_code_MODELISATION_AVEC_NLP.ipynb
>
     ğŸ¤– Ã‰tape 7 : ModÃ©lisation 3 Binaire

- Transformation de la variable cible en un modÃ¨le binaire :
  > Valeur 1 pour les notes 1 et 2.
  > 
  > Valeur 2 pour les notes 3, 4 et 5
  >

- ModÃ©lisation :
  > Tester plusieurs modÃ¨les de classification : 
      RandomForestClassifier, 
      LightGBM Classifier
  > 
  > Effectuer l'optimisation des hyperparamÃ¨tres, la validation croisÃ©e, et l'analyse des erreurs comme prÃ©cÃ©demment
  >
- RÃ©fÃ©rences notebook sur Github :
  >
  > https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/5.3_code_MODELISATION_BINAIRE_AVEC_NLP.ipynb
> 

      ğŸ§  Ã‰tape 8 : ModÃ©lisation Deep learning

-	Appliquer un modÃ¨le de rÃ©seau de neurones rÃ©current avec une couche LSTM (Long Short-Term Memory)
 
    >Ã  l'aide de la bibliothÃ¨que Keras de TensorFlow.
    >
- RÃ©fÃ©rences notebook sur Github :
    >
    >https://github.com/DataScientest-Studio/nov24_bds_supplychain/blob/main/notebooks/6_code_MODELISATION_DeepLearning_RRN.ipynb



## ğŸ“¦ Principales BibliothÃ¨ques et Outils UtilisÃ©s

Python : langage de programmation

Pandas : bibliothÃ¨que Python pour la manipulation et l'analyse de donnÃ©es

Scikit-learn : bibliothÃ¨que Python pour le machine learning

NLTK / SpaCy: bibliothÃ¨ques Python pour le traitement du langage naturel (NLP).

Matplotlib / Seaborn : bibliothÃ¨ques Python de visualisation de donnÃ©es en Python.

BeautifulSoup : bibliothÃ¨ques Python utilisÃ©e pour le web scraping

WordCloud : bibliothÃ¨que Python utilisÃ©e pour gÃ©nÃ©rer des nuages de mots Ã  partir de textes, permettant de visualiser les mots les plus frÃ©quents dans un corpus.

Statsmodels : bibliothÃ¨que Python utilisÃ©e pour l'estimation de modÃ¨les statistiques et l'analyse des donnÃ©es.

Imbalanced-learn : bibliothÃ¨que Python pour le traitement des ensembles de donnÃ©es dÃ©sÃ©quilibrÃ©s.

Scipy : UtilisÃ© pour des opÃ©rations scientifiques et techniques, y compris des outils pour l'optimisation et les statistiques.

GridSearchCV / RandSearchCV : Outil de Scikit-learn pour l'optimisation des hyperparamÃ¨tres.
## Auteurs

- ğŸ‘¨â€ğŸ’»  [@Magali864](https://www.github.com/Magali864)
- ğŸ‘¨â€ğŸ’» [@mcdieye](https://github.com/mcdieye)
- ğŸ‘¨â€ğŸ’» [@DonaBN](https://github.com/DonaBN)
- ğŸ‘¨â€ğŸ’» [@yassinetazit](https://github.com/yassinetazit)

  
